{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import catalyst\n",
    "# import pytorch_toolbelt\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions from Andrew Lukyanenko's awesome Kaggle notebook\n",
    "\n",
    "https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n",
    "    '''\n",
    "    Decode rle encoded mask.\n",
    "    :param mask_rle: run-length as string formatted (start length)\n",
    "    :param shape: (height, width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \"\"\"\n",
    "    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "\n",
    "    for idx, label in enumerate(encoded_masks.values):\n",
    "        if label is not np.nan:\n",
    "            mask = rle_decode(label)\n",
    "            masks[:, :, idx] = mask\n",
    "            \n",
    "    return masks\n",
    "\n",
    "def get_image(ind, gray=True):\n",
    "    img = cv2.imread(os.path.join(train_imgs, os.listdir(train_imgs)[ind]))\n",
    "    if gray:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\aresf\\\\Code\\\\datasets\\\\understanding_cloud_organization\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "train_df[\"Label\"] = train_df[\"Image_Label\"].apply(lambda x: x.split('_')[1])\n",
    "train_df[\"Image\"] = train_df[\"Image_Label\"].apply(lambda x: x.split('_')[0])\n",
    "# train_df = train_df.drop([\"Image_Label\"], axis=1)\n",
    "\n",
    "train_imgs = os.path.join(data_path, \"train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
    "sub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "sub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df\n",
    "train[\"label_cat\"] = pd.Categorical(train.Label).codes\n",
    "train[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.iloc[2].EncodedPixels) != np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Label</th>\n",
       "      <th>Image</th>\n",
       "      <th>label_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011165.jpg_Fish</td>\n",
       "      <td>264918 937 266318 937 267718 937 269118 937 27...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0011165.jpg_Flower</td>\n",
       "      <td>1355565 1002 1356965 1002 1358365 1002 1359765...</td>\n",
       "      <td>Flower</td>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0011165.jpg_Gravel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gravel</td>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011165.jpg_Sugar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002be4f.jpg_Fish</td>\n",
       "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002be4f.jpg_Flower</td>\n",
       "      <td>1339279 519 1340679 519 1342079 519 1343479 51...</td>\n",
       "      <td>Flower</td>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002be4f.jpg_Gravel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gravel</td>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002be4f.jpg_Sugar</td>\n",
       "      <td>67495 350 68895 350 70295 350 71695 350 73095 ...</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label                                      EncodedPixels  \\\n",
       "0    0011165.jpg_Fish  264918 937 266318 937 267718 937 269118 937 27...   \n",
       "1  0011165.jpg_Flower  1355565 1002 1356965 1002 1358365 1002 1359765...   \n",
       "2  0011165.jpg_Gravel                                                NaN   \n",
       "3   0011165.jpg_Sugar                                                NaN   \n",
       "4    002be4f.jpg_Fish  233813 878 235213 878 236613 878 238010 881 23...   \n",
       "5  002be4f.jpg_Flower  1339279 519 1340679 519 1342079 519 1343479 51...   \n",
       "6  002be4f.jpg_Gravel                                                NaN   \n",
       "7   002be4f.jpg_Sugar  67495 350 68895 350 70295 350 71695 350 73095 ...   \n",
       "\n",
       "    Label        Image  label_cat  \n",
       "0    Fish  0011165.jpg          0  \n",
       "1  Flower  0011165.jpg          1  \n",
       "2  Gravel  0011165.jpg          2  \n",
       "3   Sugar  0011165.jpg          3  \n",
       "4    Fish  002be4f.jpg          0  \n",
       "5  Flower  002be4f.jpg          1  \n",
       "6  Gravel  002be4f.jpg          2  \n",
       "7   Sugar  002be4f.jpg          3  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounded_image(idx, area_thresh=80000, resize=True):\n",
    "    '''Note that it's possible there's a bug in get_images()'''\n",
    "    image_cache = []\n",
    "    label_cache = []\n",
    "    im_idx = np.floor(idx/4).astype(np.uint16)\n",
    "    \n",
    "    for cat_idx in range(4):\n",
    "        # Make a bounding box for each mask and return a grayscale image of the clouds in the mask
    "        if  type(train.iloc[idx+cat_idx].EncodedPixels) != np.float:\n",
    "            mask = rle_decode(train.iloc[idx+cat_idx].EncodedPixels)\n",
    "            mask_ = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "            mask_[:,:,1] = mask.astype(np.uint8)\n",
    "            mask_ = mask_.astype(np.uint8)\n",
    "            mask_ = cv2.cvtColor(mask_,cv2.COLOR_BGR2GRAY)\n",
    "            ret, thresh = cv2.threshold(mask_, 0, 1, 0)\n",
    "            countours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contour_sizes = [(cv2.contourArea(contour), contour) for contour in countours]\n",
    "\n",
    "            ids = np.argsort([k[0] for k in contour_sizes])[-4::]\n",
    "            biggest_contours = [contour_sizes[i] for i in ids if contour_sizes[i][0] >= area_thresh]\n",
    "\n",
    "            for i,j in enumerate(biggest_contours):\n",
    "                x,y,w,h = cv2.boundingRect(j[1])\n",
    "                image_cache.append(im[y:y+h, x:x+w])\n",
    "                label_cache.append(cat_idx)\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "    return image_cache, label_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 2s\n"
     ]
    }
   ],
   "source": [
    " # put everything together to write into a file
    "%time imgs, labels = map(list, zip(*[get_bounded_image(k) for k in np.arange(0, train.shape[0], 4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file
    "# np.save(\"C:\\\\Users\\\\aresf\\\\Code\\\\datasets\\\\bounded_images\", imgs)\n",
    "# np.save(\"C:\\\\Users\\\\aresf\\\\Code\\\\datasets\\\\boundes_labels\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
